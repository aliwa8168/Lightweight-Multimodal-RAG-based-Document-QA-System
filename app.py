# app.py
# è½»é‡å¤šæ¨¡æ€å¤š PDF æ–‡æ¡£åº“ + RAG + æº¯æº + Web å‰ç«¯ï¼ˆDeepSeek APIï¼‰
# streamlit run app.py
import os
import streamlit as st
import fitz  # PyMuPDF
import easyocr
import numpy as np
from PIL import Image
import io

from langchain_core.documents import Document
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.chat_models import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# ============ é¡µé¢è®¾ç½® ============
st.set_page_config(page_title="Multimodal RAG QA", layout="wide")
st.title("å¤å¤ AI Â· è½»é‡å¤šæ¨¡æ€çŸ¥è¯†é—®ç­”ç³»ç»Ÿ")

# ============ DeepSeek API Key ============
os.environ["OPENAI_API_KEY"] = st.secrets.get("DEEPSEEK_API_KEY", "")
os.environ["OPENAI_API_BASE"] = "https://api.deepseek.com/v1"

# ============ åˆå§‹åŒ– Session State ============
if "vectorstore" not in st.session_state:
    st.session_state.vectorstore = None
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# ============ EasyOCR åˆå§‹åŒ– ============
@st.cache_resource
def load_ocr():
    return easyocr.Reader(['ch_sim', 'en'], gpu=False)

ocr_reader = load_ocr()

# ============ Sidebar: ä¸Šä¼  PDF ============
st.sidebar.header("ä¸Šä¼  PDF æ–‡æ¡£")
files = st.sidebar.file_uploader("ä¸Šä¼ å¤šä¸ª PDF æ–‡ä»¶", type="pdf", accept_multiple_files=True)

# ============ PDF å›¾ç‰‡æŠ½å– + OCR ============
def extract_images_and_ocr(pdf_path):
    doc = fitz.open(pdf_path)
    image_texts = []

    for page_num in range(len(doc)):
        page = doc[page_num]
        images = page.get_images(full=True)

        for img_index, img in enumerate(images):
            xref = img[0]
            base_image = doc.extract_image(xref)
            image_bytes = base_image["image"]

            image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
            image_np = np.array(image)

            results = ocr_reader.readtext(image_np)

            text = ""
            for (bbox, word, prob) in results:
                text += word + " "

            if text.strip():
                image_texts.append(
                    Document(
                        page_content=text,
                        metadata={
                            "source": pdf_path,
                            "page": page_num + 1,
                            "type": "image_ocr"
                        }
                    )
                )

    return image_texts

# ============ æ„å»ºå‘é‡æ•°æ®åº“ ============
@st.cache_resource(show_spinner=False)
def build_vectorstore(files):
    docs = []

    for file in files:
        with open(file.name, "wb") as f:
            f.write(file.getbuffer())

        # 1ï¸âƒ£ æ–‡æœ¬åŠ è½½
        loader = PyPDFLoader(file.name)
        text_docs = loader.load()

        # 2ï¸âƒ£ å›¾ç‰‡ OCR
        image_docs = extract_images_and_ocr(file.name)

        docs.extend(text_docs)
        docs.extend(image_docs)

    splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=50
    )

    chunks = splitter.split_documents(docs)

    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2"
    )

    vectorstore = FAISS.from_documents(chunks, embeddings)
    return vectorstore

if files and st.sidebar.button("æ„å»ºå¤šæ¨¡æ€æ–‡æ¡£å‘é‡åº“"):
    with st.spinner("æ­£åœ¨æ„å»ºå¤šæ¨¡æ€å‘é‡æ•°æ®åº“..."):
        st.session_state.vectorstore = build_vectorstore(files)
    st.sidebar.success("å¤šæ¨¡æ€æ–‡æ¡£åº“æ„å»ºå®Œæˆ")

# ============ RAG æ„å»º ============
def get_rag_chain(vectorstore):
    retriever = vectorstore.as_retriever(search_kwargs={"k": 4})

    llm = ChatOpenAI(
        model="deepseek-chat",
        temperature=0.2
    )

    prompt = ChatPromptTemplate.from_template(
        """
ä½ æ˜¯ä¸€ä¸ªåŸºäºæ–‡æ¡£çš„ä¸“ä¸šé—®ç­”åŠ©æ‰‹ï¼Œè¯·ä¸¥æ ¼ä¾æ®ã€ä¸Šä¸‹æ–‡ã€‘å†…å®¹è¿›è¡Œå›ç­”ã€‚

ã€å†å²å¯¹è¯ã€‘
{history}

ã€ä¸Šä¸‹æ–‡ã€‘
{context}

ã€é—®é¢˜ã€‘
{question}

è¯·ç»™å‡ºå‡†ç¡®å›ç­”ï¼Œå¹¶åœ¨æœ€ååˆ—å‡ºå¼•ç”¨çš„æ–‡æ¡£æ¥æºä¸é¡µç ã€‚
"""
    )

    chain = (
        {
            "context": lambda x: retriever.invoke(x["question"]),
            "question": lambda x: x["question"],
            "history": lambda x: x["history"],
        }
        | prompt
        | llm
        | StrOutputParser()
    )

    return chain

# ============ èŠå¤©çª—å£ ============
st.subheader("å¤šæ¨¡æ€æ–‡æ¡£é—®ç­”")

query = st.text_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜")

if st.button("æé—®"):
    if st.session_state.vectorstore is None:
        st.warning("è¯·å…ˆä¸Šä¼ å¹¶æ„å»ºå¤šæ¨¡æ€æ–‡æ¡£å‘é‡åº“")
    else:
        rag_chain = get_rag_chain(st.session_state.vectorstore)

        result = rag_chain.invoke({
            "question": query,
            "history": "\n".join(st.session_state.chat_history)
        })

        st.session_state.chat_history.append(f"ç”¨æˆ·ï¼š{query}")
        st.session_state.chat_history.append(f"åŠ©æ‰‹ï¼š{result}")

# ============ æ˜¾ç¤ºå†å²å¯¹è¯ ============
for msg in st.session_state.chat_history:
    if msg.startswith("ç”¨æˆ·"):
        st.markdown(f"**ğŸ§‘ {msg}**")
    else:
        st.markdown(f"ğŸ¤– {msg}")